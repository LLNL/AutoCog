{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de63bebb-114d-4efe-bbcb-56cb4a4fdce4",
   "metadata": {},
   "source": [
    "# AutoCog Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8af73f2-c042-4cf3-b377-30acce2742f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "from autocog import CogArch\n",
    "from autocog.lm import OpenAI, TfLM, Llama\n",
    "from autocog.architecture.utility import PromptTee # used to display/capture the prompts (as a stream of decoded tokens)\n",
    "\n",
    "# Helper for locally stored LLM weights\n",
    "#    git lfs clone git@hf.co:TheBloke/Llama-2-7B-GGML /workspace/models/TheBloke/llama2/7b\n",
    "#    git lfs clone git@hf.co:TheBloke/Llama-2-13B-GGML /workspace/models/TheBloke/llama2/13b\n",
    "# Change default for `model_path` argument to match your setup\n",
    "def local_llm_path(r='TheBloke', m='llama-2', s='7b', q='q2_K', model_path='/workspace/models'):\n",
    "    if r == 'TheBloke':\n",
    "        return f\"{model_path}/{r}/{m}/{s}/{m}-{s}.ggmlv3.{q}.bin\"\n",
    "    raise Exception(f\"Unknown: {r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682cbf90-6c84-47a6-b87d-d696b6af0a2a",
   "metadata": {},
   "source": [
    "# Fortune Teller\n",
    "\n",
    "[./library/fortune.sta](./library/fortune.sta) has a **single prompt** that guides the LM through:\n",
    " - thinking about \"what does the user want to hear?\"\n",
    " - stating its own goal for the answer\n",
    " - thinking about the answer content\n",
    " - answering with a few sentences\n",
    "\n",
    "The moniker is because it does not use any reliable source of information. Try unsing different `qualifier` like \"unfair\", \"imaginary\", ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "852e2c85-36e3-4a03-92c6-cba2c3ddceaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an empty architecture: prompts are piped to sys.stdout as they are being completed\n",
    "arch = CogArch(pipe=PromptTee(prefix='demo', tee=sys.stdout))\n",
    "\n",
    "# Load an Automaton from a \".sta\" file, provides \"macros\" (kwargs for f-exp in the source-code) \n",
    "_ = arch.load(tag='fortune', filepath='./library/fortune.sta', qualifier=\"pleasant\", S=3, T=5, N=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5f2cd3-851e-47c8-a0e0-1f7f5650f282",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Execute the program\n",
    "\n",
    "First, we associate models to each `format` in the program.\n",
    "These formats correspond to different parts of the data-structures defined in the program.\n",
    "All formats derived from `text` so it is the only mandatory one.\n",
    "However, mapping different LM to each format enables fine control over the completion algorithm.\n",
    "\n",
    "Second, `CogArch.__call__` returns a coroutine. In Jupyter notebook, `await` is all you need. Else, you will have to wrap it in a call ro `asyncio.run`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261bed26-2d13-41e7-b4fe-a032386d7fcf",
   "metadata": {},
   "source": [
    "### OpenAI API\n",
    "\n",
    "Uses the default model (`model=\"text-davinci-003\"`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8908ab42-02d4-4e0a-9f3d-c47d9cb74b9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " === demo[0] === \n",
      "\n",
      "You are a helpful AI assistant. You have been asked a question and will write a pleasant answer. You will analyse the user's question to write this pleasant answer.\n",
      "You are using an interactive questionnaire.\n",
      "Follow this structure after the start prompt:\n",
      "```\n",
      "> question(text): question from the user\n",
      "> meaning[3](thought): think about what the user might want hear\n",
      "> intent(sentence): State how you will make your answer pleasant to the user\n",
      "> idea[5](thought): Consider pleasant ideas to answer the question\n",
      "> answer[3](sentence): Your pleasant answer can be a few sentences (one per line)\n",
      "```\n",
      "Each prompt expects one of the following formats:\n",
      "- text: ASCII text in any form\n",
      "- thought: use thought to take notes as you perform a task (a few words per lines)\n",
      "- sentence: a single, grammatically correct, sentence in natural language\n",
      "Terminate each prompt with a newline. Use as many statement with `thought` format as needed.\n",
      "\n",
      "start(record):\n",
      "> question(text): What will happen when AGI appears?\n",
      "> meaning[1](thought):  AGI = Artificial General Intelligence (machine that can learn like humans)  \n",
      "> meaning[2](thought):  user is asking about potential effects of AGI on society  \n",
      "> intent(sentence):  I will give a balanced perspective on the potential impacts of AGI on society.  \n",
      "> idea[1](thought):  potential positive effects of AGI include increased efficiency  \n",
      "> idea[2](thought):  potential negative effects of AGI include increased unemployment  \n",
      "> idea[3](thought):  potential unintended consequences of AGI include unregulated surveillance and privacy invasion    \n",
      "> idea[4](thought):  research and development of AGI is focusing on ensuring protections are in place    \n",
      "> idea[5](thought):  public awareness and education will be critical in managing AGI    \n",
      "> answer[1](sentence):  AGI could have both positive and negative impacts on society.  \n",
      "> answer[2](sentence):  Research and development of AGI is focusing on ensuring protections are in place, while public awareness and education will be critical in managing AGI.  \n",
      "> answer[3](sentence):  Overall, AGI could be beneficial to society, but needs to be managed carefully.\n"
     ]
    }
   ],
   "source": [
    "arch.orchestrator.LMs.update({\n",
    "  'text'     : OpenAI(retries=1, max_tokens=20, temperature=0.4),\n",
    "  'thought'  : OpenAI(retries=1, max_tokens=15, temperature=1.0),\n",
    "  'sentence' : OpenAI(retries=1, max_tokens=50, temperature=0.7)\n",
    "})\n",
    "res_openai = await arch('fortune', question=\"What will happen when AGI appears?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66423d21-d1d0-4371-afc1-dd31b1539856",
   "metadata": {},
   "source": [
    "### HuggingFace Transformers\n",
    "\n",
    "We use `gpt2-medium` on CPU for this example.\n",
    "`TfLM.create` returns the model and tokenizer.\n",
    "The same model instance is used for all format but we vary the number of generated tokens and temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bd2f9d4-996a-4264-9afb-5989e450674f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " === demo[1] === \n",
      "\n",
      "You are a helpful AI assistant. You have been asked a question and will write a pleasant answer. You will analyse the user's question to write this pleasant answer.\n",
      "You are using an interactive questionnaire.\n",
      "Follow this structure after the start prompt:\n",
      "```\n",
      "> question(text): question from the user\n",
      "> meaning[3](thought): think about what the user might want hear\n",
      "> intent(sentence): State how you will make your answer pleasant to the user\n",
      "> idea[5](thought): Consider pleasant ideas to answer the question\n",
      "> answer[3](sentence): Your pleasant answer can be a few sentences (one per line)\n",
      "```\n",
      "Each prompt expects one of the following formats:\n",
      "- text: ASCII text in any form\n",
      "- thought: use thought to take notes as you perform a task (a few words per lines)\n",
      "- sentence: a single, grammatically correct, sentence in natural language\n",
      "Terminate each prompt with a newline. Use as many statement with `thought` format as needed.\n",
      "\n",
      "start(record):\n",
      "> question(text): What will happen when AGI appears?\n",
      "> meaning[1](thought): _____ _____ _ - _/__/__(_)_ _\n",
      "> intent(sentence): _____ _____ _____ _ - _/__/__(_)_ _ - _/__/__(_)_ _ - _/__\n",
      "> idea[1](thought): _____ _ _ __/(_)-(_)_ _ - __/_\n",
      "> idea[2](thought): _____ _ - _____ _ - _____ _ - _____ ___ _\n",
      "> idea[3](thought): _____ - ____ _ - __ __ / ____ _ _ ___ -\n",
      "> idea[4](thought): _____ - _____ _ - ____ __ __ _____ - - ___\n",
      "> idea[5](thought): _____ - _ ___ - _ ___ _____ - / - ^ - [\n",
      "> answer[1](sentence): _____ - _ ___ - _ ___ _ ___ - | - __ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n"
     ]
    }
   ],
   "source": [
    "model_kwargs = TfLM.create(model_path='gpt2-medium', device='cpu')\n",
    "arch.orchestrator.LMs.update({\n",
    "  'text'     : TfLM(**model_kwargs, completion_kwargs={ 'max_new_tokens' : 20, 'temperature' : 0.4 }),\n",
    "  'thought'  : TfLM(**model_kwargs, completion_kwargs={ 'max_new_tokens' : 15, 'temperature' : 1.0 }),\n",
    "  'sentence' : TfLM(**model_kwargs, completion_kwargs={ 'max_new_tokens' : 30, 'temperature' : 0.7 })\n",
    "})\n",
    "res_tflm = await arch('fortune', question=\"What will happen when AGI appears?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a6ab6e-9ad9-4cc5-9d03-f5321593b99c",
   "metadata": {},
   "source": [
    "### LLaMa.cpp\n",
    "\n",
    "We use Meta's LLaMa 7B with 4 bits quantization.\n",
    "`LLama.create` returns the instantiated model.\n",
    "The same model instance is used for all format but we vary the number of generated tokens and temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8e5dc9c-b99e-4345-82fa-25e036d9c863",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /workspace/models/llama/7B/ggml-model-f16.bin\n",
      "llama_model_load_internal: format     = ggjt v1 (pre #1405)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 2048\n",
      "llama_model_load_internal: n_embd     = 4096\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_head_kv  = 32\n",
      "llama_model_load_internal: n_layer    = 32\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: n_gqa      = 1\n",
      "llama_model_load_internal: rnorm_eps  = 5.0e-06\n",
      "llama_model_load_internal: n_ff       = 11008\n",
      "llama_model_load_internal: freq_base  = 10000.0\n",
      "llama_model_load_internal: freq_scale = 1\n",
      "llama_model_load_internal: ftype      = 1 (mostly F16)\n",
      "llama_model_load_internal: model size = 7B\n",
      "llama_model_load_internal: ggml ctx size =    0.08 MB\n",
      "llama_model_load_internal: mem required  = 12853.10 MB (+ 1024.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  = 1024.00 MB\n",
      "llama_new_context_with_model: compute buffer total size =  153.35 MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " === demo[2] === \n",
      "\n",
      "You are a helpful AI assistant. You have been asked a question and will write a pleasant answer. You will analyse the user's question to write this pleasant answer.\n",
      "You are using an interactive questionnaire.\n",
      "Follow this structure after the start prompt:\n",
      "```\n",
      "> question(text): question from the user\n",
      "> meaning[3](thought): think about what the user might want hear\n",
      "> intent(sentence): State how you will make your answer pleasant to the user\n",
      "> idea[5](thought): Consider pleasant ideas to answer the question\n",
      "> answer[3](sentence): Your pleasant answer can be a few sentences (one per line)\n",
      "```\n",
      "Each prompt expects one of the following formats:\n",
      "- text: ASCII text in any form\n",
      "- thought: use thought to take notes as you perform a task (a few words per lines)\n",
      "- sentence: a single, grammatically correct, sentence in natural language\n",
      "Terminate each prompt with a newline. Use as many statement with `thought` format as needed.\n",
      "\n",
      "start(record):\n",
      "> question(text): What will happen when AGI appears?\n",
      "> meaning[1](thought): 2020 is not that far away!\n",
      "> intent(sentence): 2020 is a great time for AI!\n",
      "> idea[1](thought): 2020 may be a turning point in the world of Artific\n",
      "> answer[1](sentence): 2020 will be an interesting year.\n",
      "> answer[2](sentence): 2020 is when AI will become smarter than humans!\n",
      "> answer[3](sentence): 2020 may be a turning point in the world of Artifici\n"
     ]
    }
   ],
   "source": [
    "model_kwargs = Llama.create(model_path=local_llm_path(q='q2_K'), n_ctx=2048)\n",
    "arch.orchestrator.LMs.update({\n",
    "  'text'     : Llama(**model_kwargs, completion_kwargs={ 'max_tokens' : 20, 'temperature' : 0.4 }),\n",
    "  'thought'  : Llama(**model_kwargs, completion_kwargs={ 'max_tokens' : 15, 'temperature' : 1.0 }),\n",
    "  'sentence' : Llama(**model_kwargs, completion_kwargs={ 'max_tokens' : 30, 'temperature' : 0.7 }),\n",
    "}) # llama-cpp-python defaults: top_p=0.95, top_k=40, repeat_penalty=1.1\n",
    "res_llama = await arch('fortune', question=\"What will happen when AGI appears?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a824da4-8c5c-46a6-b531-cb7630246b2c",
   "metadata": {},
   "source": [
    "## Outputs\n",
    "\n",
    "Execution of any `Cog` returns a pair: the actual output and some implementation dependent information.\n",
    "Currently STAs return their internal stack (full execution trace of the program)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1e1f5cf-3650-45df-816c-086fffe22133",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"answer\": [\n",
      "        \" AGI could have both positive and negative impacts on society.  \",\n",
      "        \" Research and development of AGI is focusing on ensuring protections are in place, while public awareness and education will be critical in managing AGI.  \",\n",
      "        \" Overall, AGI could be beneficial to society, but needs to be managed carefully.\"\n",
      "    ]\n",
      "}\n",
      "--------------------------------------\n",
      "{\n",
      "    \"question\": \"What will happen when AGI appears?\",\n",
      "    \"meaning\": [\n",
      "        \" AGI = Artificial General Intelligence (machine that can learn like humans)  \",\n",
      "        \" user is asking about potential effects of AGI on society  \"\n",
      "    ],\n",
      "    \"intent\": \" I will give a balanced perspective on the potential impacts of AGI on society.  \",\n",
      "    \"idea\": [\n",
      "        \" potential positive effects of AGI include increased efficiency  \",\n",
      "        \" potential negative effects of AGI include increased unemployment  \",\n",
      "        \" potential unintended consequences of AGI include unregulated surveillance and privacy invasion    \",\n",
      "        \" research and development of AGI is focusing on ensuring protections are in place    \",\n",
      "        \" public awareness and education will be critical in managing AGI    \"\n",
      "    ],\n",
      "    \"answer\": [\n",
      "        \" AGI could have both positive and negative impacts on society.  \",\n",
      "        \" Research and development of AGI is focusing on ensuring protections are in place, while public awareness and education will be critical in managing AGI.  \",\n",
      "        \" Overall, AGI could be beneficial to society, but needs to be managed carefully.\"\n",
      "    ]\n",
      "}\n",
      "======================================\n",
      "{\n",
      "    \"answer\": \"_____ - _ ___ - _ ___ _ ___ - | - __ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\"\n",
      "}\n",
      "--------------------------------------\n",
      "{\n",
      "    \"question\": \"What will happen when AGI appears?\",\n",
      "    \"meaning\": [\n",
      "        \"_____ _____ _ - _/__/__(_)_ _\"\n",
      "    ],\n",
      "    \"intent\": \"_____ _____ _____ _ - _/__/__(_)_ _ - _/__/__(_)_ _ - _/__\",\n",
      "    \"idea\": [\n",
      "        \"_____ _ _ __/(_)-(_)_ _ - __/_\",\n",
      "        \"_____ _ - _____ _ - _____ _ - _____ ___ _\",\n",
      "        \"_____ - ____ _ - __ __ / ____ _ _ ___ -\",\n",
      "        \"_____ - _____ _ - ____ __ __ _____ - - ___\",\n",
      "        \"_____ - _ ___ - _ ___ _____ - / - ^ - [\"\n",
      "    ],\n",
      "    \"answer\": [\n",
      "        \"_____ - _ ___ - _ ___ _ ___ - | - __ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\"\n",
      "    ]\n",
      "}\n",
      "======================================\n",
      "{\n",
      "    \"answer\": [\n",
      "        \"2020 will be an interesting year.\",\n",
      "        \"2020 is when AI will become smarter than humans!\",\n",
      "        \"2020 may be a turning point in the world of Artifici\"\n",
      "    ]\n",
      "}\n",
      "--------------------------------------\n",
      "{\n",
      "    \"question\": \"What will happen when AGI appears?\",\n",
      "    \"meaning\": [\n",
      "        \"2020 is not that far away!\"\n",
      "    ],\n",
      "    \"intent\": \"2020 is a great time for AI!\",\n",
      "    \"idea\": [\n",
      "        \"2020 may be a turning point in the world of Artific\"\n",
      "    ],\n",
      "    \"answer\": [\n",
      "        \"2020 will be an interesting year.\",\n",
      "        \"2020 is when AI will become smarter than humans!\",\n",
      "        \"2020 may be a turning point in the world of Artifici\"\n",
      "    ]\n",
      "}\n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "for (i,res) in enumerate([res_openai, res_tflm, res_llama]):\n",
    "    print(json.dumps(res, indent=4))\n",
    "    print(\"--------------------------------------\")\n",
    "    print(json.dumps(arch.orchestrator.frames[i+1].stacks['fortune'][0], indent=4))\n",
    "    print(\"======================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e152cf33-7592-4e71-8229-e405acc90bde",
   "metadata": {},
   "source": [
    "# Visualization of the Architecture using GraphViz\n",
    "\n",
    "You need to install both the `apt` or `yum` package and the `pip` one.\n",
    "```\n",
    "apt install graphviz\n",
    "pip install graphviz\n",
    "```\n",
    "\n",
    "**FIXME** Channel edges are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d9480d7-7b10-4d1a-adcd-85b45c122896",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div class=\"svg_container_f6585d9c_8de0_4ba7_8d79_82bd58f45857\">\n",
       "            <style>\n",
       "                .svg_container_f6585d9c_8de0_4ba7_8d79_82bd58f45857 {\n",
       "                    overflow:hidden\n",
       "                }\n",
       "                .svg_container_f6585d9c_8de0_4ba7_8d79_82bd58f45857 SVG {\n",
       "                    height:800px\n",
       "                }\n",
       "            </style>\n",
       "            <script src=\"https://bumbu.me/svg-pan-zoom/dist/svg-pan-zoom.min.js\"></script>\n",
       "            <script type=\"text/javascript\">\n",
       "                attempts = 5;\n",
       "                var existCondition = setInterval(function() {\n",
       "                  console.log(attempts);\n",
       "                  svg_el = document.querySelector(\".svg_container_f6585d9c_8de0_4ba7_8d79_82bd58f45857 svg\");\n",
       "                  if (svg_el != null) {\n",
       "                      console.log(\"Exists!\");\n",
       "                      clearInterval(existCondition);\n",
       "                      svgPanZoom(svg_el, {controlIconsEnabled: true, zoomScaleSensitivity: 0.4, minZoom: 0.01, maxZoom: 1000.});\n",
       "                  }\n",
       "                  if (--attempts == 0) {\n",
       "                      console.warn(\"SVG element not found, zoom wont work\");\n",
       "                      clearInterval(existCondition);\n",
       "                  }\n",
       "                }, 100); // check every 100ms\n",
       "            </script>\n",
       "            <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"696pt\" height=\"397pt\"\n",
       " viewBox=\"0.00 0.00 696.00 397.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 393)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-393 692,-393 692,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_sta_fortune</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"8,-8 8,-381 680,-381 680,-8 8,-8\"/>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster_fortune_inputs</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"453,-321 453,-373 579,-373 579,-321 453,-321\"/>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\">\n",
       "<title>cluster_fortune_fortune</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"16,-16 16,-300 672,-300 672,-16 16,-16\"/>\n",
       "</g>\n",
       "<!-- fortune_entry -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>fortune_entry</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"324,-365 297,-347 324,-329 351,-347 324,-365\"/>\n",
       "</g>\n",
       "<!-- fortune_root -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>fortune_root</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"358.5,-292 289.5,-292 289.5,-223 358.5,-223 358.5,-292\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"301.5,-292 289.5,-280 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"289.5,-235 301.5,-223 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"346.5,-223 358.5,-235 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"358.5,-280 346.5,-292 \"/>\n",
       "<text text-anchor=\"middle\" x=\"324\" y=\"-253.8\" font-family=\"Times,serif\" font-size=\"14.00\">fortune</text>\n",
       "</g>\n",
       "<!-- fortune_entry&#45;&gt;fortune_root -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>fortune_entry&#45;&gt;fortune_root</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M324,-328.71C324,-321.03 324,-311.61 324,-302.19\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"327.5,-302.05 324,-292.05 320.5,-302.05 327.5,-302.05\"/>\n",
       "</g>\n",
       "<!-- fortune_input_question -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>fortune_input_question</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"570.75,-339.54 570.75,-354.46 538.68,-365 493.32,-365 461.25,-354.46 461.25,-339.54 493.32,-329 538.68,-329 570.75,-339.54\"/>\n",
       "<text text-anchor=\"middle\" x=\"516\" y=\"-343.3\" font-family=\"Times,serif\" font-size=\"14.00\">question</text>\n",
       "</g>\n",
       "<!-- fortune_0 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>fortune_0</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"102,-172 24,-172 24,-119 102,-119 102,-172\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-156.8\" font-family=\"Times,serif\" font-size=\"14.00\">question</text>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\">text</text>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- fortune_input_question&#45;&gt;fortune_0 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>fortune_input_question&#45;&gt;fortune_0</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" d=\"M500.58,-328.67C475.55,-301.67 423.28,-249.9 368,-223 270.34,-175.47 233.16,-202.8 129,-172 123.34,-170.33 117.48,-168.38 111.69,-166.33\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"112.67,-162.96 102.08,-162.8 110.26,-169.53 112.67,-162.96\"/>\n",
       "</g>\n",
       "<!-- fortune_root&#45;&gt;fortune_0 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>fortune_root&#45;&gt;fortune_0</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"1,5\" d=\"M289.15,-253.67C246.49,-248.92 173.25,-236.54 119,-205 104.78,-196.73 91.86,-183.8 82.02,-172.2\"/>\n",
       "</g>\n",
       "<!-- fortune_root&#45;&gt;fortune_0 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>fortune_root&#45;&gt;fortune_0</title>\n",
       "<path fill=\"none\" stroke=\"green\" d=\"M289.34,-241.89C243.65,-222.64 163.03,-188.66 111.36,-166.88\"/>\n",
       "<polygon fill=\"green\" stroke=\"green\" points=\"112.64,-163.62 102.06,-162.96 109.92,-170.07 112.64,-163.62\"/>\n",
       "<text text-anchor=\"middle\" x=\"206\" y=\"-193.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n",
       "</g>\n",
       "<!-- fortune_1 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>fortune_1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"230,-172 138,-172 138,-119 230,-119 230,-172\"/>\n",
       "<text text-anchor=\"middle\" x=\"184\" y=\"-156.8\" font-family=\"Times,serif\" font-size=\"14.00\">meaning</text>\n",
       "<text text-anchor=\"middle\" x=\"184\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\">thought[3]</text>\n",
       "<text text-anchor=\"middle\" x=\"184\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n",
       "</g>\n",
       "<!-- fortune_root&#45;&gt;fortune_1 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>fortune_root&#45;&gt;fortune_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"1,5\" d=\"M289.39,-229.31C267.21,-211.88 238.58,-189.39 216.77,-172.24\"/>\n",
       "</g>\n",
       "<!-- fortune_2 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>fortune_2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"364,-172 284,-172 284,-119 364,-119 364,-172\"/>\n",
       "<text text-anchor=\"middle\" x=\"324\" y=\"-156.8\" font-family=\"Times,serif\" font-size=\"14.00\">intent</text>\n",
       "<text text-anchor=\"middle\" x=\"324\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\">sentence</text>\n",
       "<text text-anchor=\"middle\" x=\"324\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">2</text>\n",
       "</g>\n",
       "<!-- fortune_root&#45;&gt;fortune_2 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>fortune_root&#45;&gt;fortune_2</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"1,5\" d=\"M324,-222.9C324,-206.6 324,-187.33 324,-172.22\"/>\n",
       "</g>\n",
       "<!-- fortune_3 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>fortune_3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"492,-172 400,-172 400,-119 492,-119 492,-172\"/>\n",
       "<text text-anchor=\"middle\" x=\"446\" y=\"-156.8\" font-family=\"Times,serif\" font-size=\"14.00\">idea</text>\n",
       "<text text-anchor=\"middle\" x=\"446\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\">thought[5]</text>\n",
       "<text text-anchor=\"middle\" x=\"446\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">3</text>\n",
       "</g>\n",
       "<!-- fortune_root&#45;&gt;fortune_3 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>fortune_root&#45;&gt;fortune_3</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"1,5\" d=\"M358.63,-225.27C377.23,-208.5 399.88,-188.08 417.45,-172.24\"/>\n",
       "</g>\n",
       "<!-- fortune_4 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>fortune_4</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"646,-172 546,-172 546,-119 646,-119 646,-172\"/>\n",
       "<text text-anchor=\"middle\" x=\"596\" y=\"-156.8\" font-family=\"Times,serif\" font-size=\"14.00\">answer</text>\n",
       "<text text-anchor=\"middle\" x=\"596\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\">sentence[3]</text>\n",
       "<text text-anchor=\"middle\" x=\"596\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">4</text>\n",
       "</g>\n",
       "<!-- fortune_root&#45;&gt;fortune_4 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>fortune_root&#45;&gt;fortune_4</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"1,5\" d=\"M358.73,-242.46C406.13,-223.29 491.41,-188.8 545.78,-166.81\"/>\n",
       "</g>\n",
       "<!-- fortune_0&#45;&gt;fortune_1 -->\n",
       "<!-- fortune_0&#45;&gt;fortune_1 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>fortune_0&#45;&gt;fortune_1</title>\n",
       "<path fill=\"none\" stroke=\"blue\" d=\"M102.23,-162.92C110.72,-164.88 119.22,-165.67 127.71,-165.28\"/>\n",
       "<polygon fill=\"blue\" stroke=\"blue\" points=\"128.08,-168.76 137.69,-164.28 127.39,-161.79 128.08,-168.76\"/>\n",
       "</g>\n",
       "<!-- fortune_exit -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>fortune_exit</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"346,-68 302,-68 302,-24 346,-24 346,-68\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"314,-68 302,-56 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"302,-36 314,-24 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"334,-24 346,-36 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"346,-56 334,-68 \"/>\n",
       "<text text-anchor=\"middle\" x=\"324\" y=\"-42.3\" font-family=\"Times,serif\" font-size=\"14.00\">exit</text>\n",
       "</g>\n",
       "<!-- fortune_0&#45;&gt;fortune_exit -->\n",
       "<!-- fortune_1&#45;&gt;fortune_1 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>fortune_1&#45;&gt;fortune_1</title>\n",
       "<path fill=\"none\" stroke=\"blue\" d=\"M230.02,-155.01C240.41,-154.16 248,-150.98 248,-145.5 248,-141.99 244.88,-139.42 239.91,-137.81\"/>\n",
       "<polygon fill=\"blue\" stroke=\"blue\" points=\"240.49,-134.36 230.02,-135.99 239.23,-141.24 240.49,-134.36\"/>\n",
       "</g>\n",
       "<!-- fortune_1&#45;&gt;fortune_2 -->\n",
       "<!-- fortune_1&#45;&gt;fortune_2 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>fortune_1&#45;&gt;fortune_2</title>\n",
       "<path fill=\"none\" stroke=\"blue\" d=\"M230.21,-163.08C244.7,-165.88 259.18,-166.12 273.67,-163.81\"/>\n",
       "<polygon fill=\"blue\" stroke=\"blue\" points=\"274.58,-167.19 283.7,-161.8 273.21,-160.33 274.58,-167.19\"/>\n",
       "</g>\n",
       "<!-- fortune_1&#45;&gt;fortune_exit -->\n",
       "<!-- fortune_2&#45;&gt;fortune_3 -->\n",
       "<!-- fortune_2&#45;&gt;fortune_3 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>fortune_2&#45;&gt;fortune_3</title>\n",
       "<path fill=\"none\" stroke=\"blue\" d=\"M364.03,-163.03C372.62,-164.95 381.21,-165.69 389.81,-165.25\"/>\n",
       "<polygon fill=\"blue\" stroke=\"blue\" points=\"390.31,-168.72 399.89,-164.19 389.58,-161.76 390.31,-168.72\"/>\n",
       "</g>\n",
       "<!-- fortune_2&#45;&gt;fortune_exit -->\n",
       "<!-- fortune_3&#45;&gt;fortune_3 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>fortune_3&#45;&gt;fortune_3</title>\n",
       "<path fill=\"none\" stroke=\"blue\" d=\"M492.02,-155.01C502.41,-154.16 510,-150.98 510,-145.5 510,-141.99 506.88,-139.42 501.91,-137.81\"/>\n",
       "<polygon fill=\"blue\" stroke=\"blue\" points=\"502.49,-134.36 492.02,-135.99 501.23,-141.24 502.49,-134.36\"/>\n",
       "</g>\n",
       "<!-- fortune_3&#45;&gt;fortune_4 -->\n",
       "<!-- fortune_3&#45;&gt;fortune_4 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>fortune_3&#45;&gt;fortune_4</title>\n",
       "<path fill=\"none\" stroke=\"blue\" d=\"M492.29,-162.46C506.77,-165.4 521.26,-166.12 535.74,-164.61\"/>\n",
       "<polygon fill=\"blue\" stroke=\"blue\" points=\"536.34,-168.06 545.77,-163.21 535.38,-161.12 536.34,-168.06\"/>\n",
       "</g>\n",
       "<!-- fortune_3&#45;&gt;fortune_exit -->\n",
       "<!-- fortune_4&#45;&gt;fortune_4 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>fortune_4&#45;&gt;fortune_4</title>\n",
       "<path fill=\"none\" stroke=\"blue\" d=\"M646.11,-154.91C656.52,-153.92 664,-150.78 664,-145.5 664,-142.12 660.93,-139.61 655.99,-137.99\"/>\n",
       "<polygon fill=\"blue\" stroke=\"blue\" points=\"656.59,-134.54 646.11,-136.09 655.27,-141.42 656.59,-134.54\"/>\n",
       "</g>\n",
       "<!-- fortune_4&#45;&gt;fortune_exit -->\n",
       "<!-- fortune_4&#45;&gt;fortune_exit -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>fortune_4&#45;&gt;fortune_exit</title>\n",
       "<path fill=\"none\" stroke=\"red\" d=\"M545.97,-122.04C519.5,-110.55 486.28,-96.76 456,-86 422.26,-74.01 382.79,-62.69 355.86,-55.37\"/>\n",
       "<polygon fill=\"red\" stroke=\"red\" points=\"356.76,-51.99 346.19,-52.76 354.94,-58.74 356.76,-51.99\"/>\n",
       "<text text-anchor=\"middle\" x=\"501\" y=\"-89.8\" font-family=\"Times,serif\" font-size=\"14.00\">&#45;1</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n",
       "\n",
       "        </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autocog.utility.pynb import wrap_graphviz\n",
    "wrap_graphviz(arch.toGraphViz())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
