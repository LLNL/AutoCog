{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9961830-c0f6-4d46-a8ee-ab6ea6e0fefa",
   "metadata": {},
   "source": [
    "# Finite Thoughts Automaton\n",
    "\n",
    "This notebook focuses on creating FTA a lower level automaton than STA which could be called a \"machine model\" for LM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3114d3d6-abcb-4ba5-91dc-8aa87b82312f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "sys.path.append(\"/home/tristan/projects/LLM/AutoCog\")\n",
    "#from autocog.lm import TfLM, OpenAI, Llama\n",
    "#llama_path = lambda x: \"/workspace/models/{}/ggml-model-{}.bin\".format(*x)\n",
    "#llm = Llama(**Llama.create(model_path=llama_path(('7B','q4_0')), n_ctx=2048), max_tokens=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a20f6cda-50b3-4c5c-a674-5704f59c16ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Package `llama_cpp` needed for LLaMa wrapper (pip install git+https://github.com/tristanvdb/llama-cpp-python@choice-dev)\n",
      "Warning: Package `transformers` needed for (Huggingface's) transformers wrapper\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autocog.lm.local'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautocog\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautomatons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautomaton\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FiniteThoughtAutomaton \u001b[38;5;28;01mas\u001b[39;00m FTA\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautocog\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautomatons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Choose, Complete, Text\n\u001b[1;32m      4\u001b[0m nonzero_digits \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m6\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m7\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m8\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m9\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/projects/LLM/AutoCog/autocog/automatons/fta/automaton.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvocab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Token\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Action, Choose\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LM\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic_numpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NDArrayFp32\n",
      "File \u001b[0;32m~/projects/LLM/AutoCog/autocog/automatons/fta/actions.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvocab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Vocab, Token\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchoice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TokenChoiceTree\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlocal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TokenizerLM\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAction\u001b[39;00m(BaseModel):\n\u001b[1;32m     13\u001b[0m     uid: \u001b[38;5;28mstr\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'autocog.lm.local'"
     ]
    }
   ],
   "source": [
    "from autocog.automatons.fta.automaton import FiniteThoughtAutomaton as FTA\n",
    "from autocog.automatons.fta.actions import Choose, Complete, Text\n",
    "\n",
    "nonzero_digits = ['1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "fta = FTA(lm=llm)\n",
    "subject   = fta.create(uid='subject',   cls=Text,     successors=['qualifier'],           text=\"the speed of light in \"                                      )\n",
    "qualifier = fta.create(uid='qualifier', cls=Choose,   successors=['verb','verb','verb'],  choices=[ \"km/s\", \"m/s\", \"km/h\" ]                                  )\n",
    "verb      = fta.create(uid='verb',      cls=Text,     successors=['digits_1'],            text=\" is \"                                                        )\n",
    "digits_1  = fta.create(uid='digits_1',  cls=Complete, successors=['sep_1'],               length=3, vocab={ 'texts' : nonzero_digits }, stop=[',','.']       )\n",
    "sep_1     = fta.create(uid='sep_1',     cls=Choose,   successors=['digits_2','digits_4'], choices=[ ',', '.' ]                                               )\n",
    "digits_2  = fta.create(uid='digits_2',  cls=Complete, successors=['sep_2'],               length=3, vocab={ 'texts' : ['0']+nonzero_digits }, stop=[',','.'] )\n",
    "sep_2     = fta.create(uid='sep_2',     cls=Choose,   successors=['digits_3','digits_4'], choices=[ ',', '.' ]                                               )\n",
    "digits_3  = fta.create(uid='digits_3',  cls=Complete, successors=['sep_3'],               length=3, vocab={ 'texts' : ['0']+nonzero_digits }, stop=['.']     )\n",
    "sep_3     = fta.create(uid='sep_3',     cls=Text,     successors=['digits_4'],            text=\".\"                                                           )\n",
    "digits_4  = fta.create(uid='digits_4',  cls=Complete, successors=['eol'],                 length=2, vocab={ 'texts' : ['0']+nonzero_digits }, stop=['\\n']    )\n",
    "eol       = fta.create(uid='eol',       cls=Text,     successors=[],                      text=\"\\n\"                                                          )\n",
    "\n",
    "from autocog.utility.pynb import wrap_graphviz\n",
    "wrap_graphviz(fta.toGraphViz())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa75c60c-b6f1-4b36-b9d5-cadd4228f491",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fta.greedy('subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6109e138-ed58-4077-a22b-634b658ba555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = [\n",
    "\"\"\"> question(text): Scientists wonder how the Egyptian pyramids were built. They think that the huge blocks of stone may have been put into place by pushing them up a sloping pathway. The pathway is which type of simple machine?\n",
    "> choices[1](text): lever\n",
    "> choices[2](text): pulley\n",
    "> choices[3](text): inclined plane\n",
    "> choices[4](text): wheel and axle\"\"\"\n",
    "]\n",
    "answer = [\n",
    "\"> answer(choice): inclined plane\"\n",
    "]\n",
    "syntax = \"\"\"> question(text): The question from the MMLU Exam\n",
    "> choices[4](text): Four potential answers to the question\n",
    "> answer(choice): You choose the correct answer.\"\"\"\n",
    "formats = \"\"\"- text: any text\n",
    "- thought: short text used to prepare your answers\n",
    "- choice: index of the correct choice, one of `1`, `2`, `3`, or `4`\"\"\"\n",
    "\n",
    "patterns = [ [\n",
    "\"\"\"You are a helpful AI assistant. You are taking the MMLU exam. You are given one question and four choices for the answer. Only one of these choices is the correct answer.\n",
    "You are using an interactive questionnaire. Follow this syntax after the start prompt:\n",
    "```\n",
    "> question(text): \"\"\", { 'beams' : 3, 'length' : 10, 'stop' : '\\n' }, \"\"\"\n",
    "> choices[4](text): \"\"\", { 'beams' : 3, 'length' : 10, 'stop' : '\\n' }, \"\"\"\n",
    "> answer(choice): \"\"\", { 'beams' : 3, 'length' : 10, 'stop' : '\\n' }, \"\"\"\n",
    "```\n",
    "Each prompt expects one of the following formats:\n",
    "- text: \"\"\", { 'beams' : 3, 'length' : 10, 'stop' : '\\n', }, \"\"\"\n",
    "- choice: \"\"\", { 'beams' : 3, 'length' : 10, 'stop' : '\\n' }, \"\"\"\n",
    "Terminate each prompt with a newline.\n",
    "\n",
    "start(record):\n",
    "{inputs}\n",
    "{answer}\n",
    "\"\"\"\n",
    "],[\n",
    "\"\"\"You are a helpful AI assistant. You are taking the MMLU exam. You are given one question and four choices for the answer. Only one of these choices is the correct answer.\n",
    "You are using an interactive questionnaire. Follow this syntax after the start prompt:\n",
    "```\n",
    "{syntax}\n",
    "```\n",
    "Each prompt expects one of the following formats:\n",
    "{formats}\n",
    "Terminate each prompt with a newline.\n",
    "\n",
    "start(record):\n",
    "{inputs}\n",
    "> answer(choice): \"\"\", { 'choices' : ['1','2','3','4'] }\n",
    "],[\n",
    "\"\"\"You are a helpful AI assistant. You are taking the MMLU exam. You are given one question and four choices for the answer. Only one of these choices is the correct answer.\n",
    "You are using an interactive questionnaire. Follow this syntax after the start prompt:\n",
    "```\n",
    "{syntax}\n",
    "```\n",
    "Each prompt expects one of the following formats:\n",
    "{formats}\n",
    "Terminate each prompt with a newline.\n",
    "\n",
    "start(record):\n",
    "{inputs}\n",
    "> notepad[1](thougth):\"\"\", { 'beams' : 1, 'length' : 30, 'stop' : '\\n' }, \"\"\"\n",
    "> notepad[2](thougth):\"\"\", { 'beams' : 1, 'length' : 30, 'stop' : '\\n' }, \"\"\"\n",
    "> notepad[3](thougth):\"\"\", { 'beams' : 1, 'length' : 30, 'stop' : '\\n' }, \"\"\"\n",
    "> answer(choice): \"\"\", { 'choices' : ['1','2','3','4'] }\n",
    "] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240cf60e-7f11-4115-bb61-946cfe72d468",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tree_from_pattern(pattern, **kwargs):\n",
    "    if len(pattern) == 0:\n",
    "        return None\n",
    "    current = pattern[0]\n",
    "    if isinstance(current,str):\n",
    "        tree = Choice.build(choices=[current.format(**kwargs)], norm=False)\n",
    "    elif 'choices' in current:\n",
    "        tree = Choice.build(**current, norm=False)\n",
    "    elif 'length' in current:\n",
    "        tree = Complete.build(**current)\n",
    "    tree.successors = [ tree_from_pattern(pattern[1:], **kwargs) for s in tree.successors ]\n",
    "    return tree                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be35af93-d9a7-4f07-822f-084530825319",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ftt = FiniteThoughtTree.from_pattern(patterns[2], syntax=syntax, formats=formats, inputs=inputs[0])\n",
    "# print(json.dumps(tree.dict(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8175e2d3-3940-4fe9-89d7-3e5a4e99cede",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "llm = Llama(**Llama.create(model_path=llama_path(('7B','q4_0')), n_ctx=2048), max_tokens=20)\n",
    "res = ftt.explore(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a96bbfb-58b9-4931-91dc-10c605e0dba0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json.dump(tree.dict(), open('ftt.json','w'), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76953a6e-d986-4c6f-8980-ac24cc15720b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = list(tree.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f855426-26d6-4527-8b7e-733dc69e1dd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for r in sorted(results, key=lambda x: x[1], reverse=True):\n",
    "    print(f\"Proba: {r[1]}\")\n",
    "    print('    '+'\\n    '.join(r[0].split('\\n')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53d0fd2-be52-485e-acf5-0e1f80a6bd20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(json.dumps(tree.dict(), indent=4))\n",
    "for (text,proba,path) in sorted(results,key=lambda x: x[1]):\n",
    "    print(f'> \"{text}\": {proba} ({path})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
