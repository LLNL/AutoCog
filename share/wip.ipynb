{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d781efe-6b68-4ea9-b39a-1e112f47e31a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Package `transformers` needed for (Huggingface's) transformers wrapper\n"
     ]
    }
   ],
   "source": [
    "import os, sys, json\n",
    "\n",
    "autocog_home = os.path.realpath(f\"{os.getcwd()}/../\")\n",
    "sys.path.append(autocog_home)\n",
    "\n",
    "from autocog import CogArch\n",
    "from autocog.sta.syntax import Syntax\n",
    "\n",
    "from autocog.utility.pynb import wrap_graphviz, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f95fe5c-fa44-426d-93ca-94cdd0acbdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocog.lm import RLM\n",
    "from autocog.lm import Llama\n",
    "\n",
    "models_path = \"/data/models\"\n",
    "# model_name = None # Use random generator for ultra fast regression testing\n",
    "# model_name = 'llama-2-7b.Q4_K_M'                 # wget https://huggingface.co/TheBloke/Llama-2-7B-GGUF/resolve/main/llama-2-7b.Q4_K_M.gguf\n",
    "# model_name = 'llama-2-7b-chat.Q4_K_M'            # wget https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q4_K_M.gguf\n",
    "# model_name = 'tinyllama-1.1b-chat-v0.3.Q4_K_M'   # wget https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v0.3-GGUF/resolve/main/tinyllama-1.1b-chat-v0.3.Q4_K_M.gguf\n",
    "model_name = 'tinyllama-2-1b-miniguanaco.Q4_K_M' # wget https://huggingface.co/TheBloke/Tinyllama-2-1b-miniguanaco-GGUF/resolve/main/tinyllama-2-1b-miniguanaco.Q4_K_M.gguf\n",
    "n_ctx = 4096\n",
    "\n",
    "if model_name is None:\n",
    "    lm = RLM()\n",
    "    syntax = Syntax()\n",
    "else:\n",
    "    lm = Llama(model_path=f\"{models_path}/{model_name}.gguf\", n_ctx=n_ctx)\n",
    "    if model_name.find('llama-2') >= 0 and model_name.find('chat') >= 0:\n",
    "        syntax = Syntax.Llama2Chat()\n",
    "    if model_name.find('tinyllama') >= 0 and model_name.find('chat') >= 0:\n",
    "        syntax = Syntax.ChatML()\n",
    "    if model_name.find('tinyllama') >= 0 and model_name.find('miniguanaco') >= 0:\n",
    "        syntax = Syntax.Guanaco()\n",
    "    else:\n",
    "        syntax = Syntax()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a2ec56b-474e-4ac2-890e-051c3c28ae0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# r = [ lm.tokenize('the weather sucks', whole=False), [lm.model.token_nl()], lm.tokenize('next:', whole=False), lm.tokenize('\\nnext:') ]\n",
    "# print(r)\n",
    "# print(lm.tokenize('>'))\n",
    "# print(lm.tokenize('the weather sucks\\nnext:'))\n",
    "# # lm.model.token_nl()\n",
    "# lm.detokenize([lm.model.token_nl()]+r[0]+r[1]+r[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ba1f96a-4dab-481c-bb78-1bf0eedb36a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens = lm.tokenize('16', whole=False)\n",
    "# lm.detokenize(tokens, whole=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8138764-3184-4596-a240-eab802166f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [].endswith()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1551e566-0746-4310-bb9f-01ebb402e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = CogArch(lm=lm, syntax=syntax)\n",
    "\n",
    "mmlu_cogs = [\n",
    "    arch.load('mmlu-repeat',                filepath=f\"{autocog_home}/library/mmlu-exams/repeat.sta\"),\n",
    "    arch.load('mmlu-repeat-cot',            filepath=f\"{autocog_home}/library/mmlu-exams/repeat-cot.sta\"),\n",
    "    arch.load('mmlu-repeat-hyp',            filepath=f\"{autocog_home}/library/mmlu-exams/repeat-hyp.sta\"),\n",
    "    arch.load('mmlu-repeat-iter',           filepath=f\"{autocog_home}/library/mmlu-exams/repeat-iter.sta\"),\n",
    "    arch.load('mmlu-repeat-annot',          filepath=f\"{autocog_home}/library/mmlu-exams/repeat-annot.sta\"),\n",
    "    arch.load('mmlu-select',                filepath=f\"{autocog_home}/library/mmlu-exams/select.sta\"),\n",
    "    arch.load('mmlu-select-cot',            filepath=f\"{autocog_home}/library/mmlu-exams/select-cot.sta\"),\n",
    "    arch.load('mmlu-select-hyp',            filepath=f\"{autocog_home}/library/mmlu-exams/select-hyp.sta\"),\n",
    "    arch.load('mmlu-select-iter',           filepath=f\"{autocog_home}/library/mmlu-exams/select-iter.sta\"),\n",
    "    arch.load('mmlu-select-annot',          filepath=f\"{autocog_home}/library/mmlu-exams/select-annot.sta\")\n",
    "]\n",
    "\n",
    "mmlu_data = [\n",
    "    {\n",
    "        \"topic\"    : \"arithmetic\",\n",
    "        \"question\" : \"What is 3*4+9?\",\n",
    "        \"choices\"  : [ \"16\", \"21\", \"39\", \"42\" ]\n",
    "    }\n",
    "]\n",
    "\n",
    "arith_cogs = [\n",
    "    arch.load('arithmetic-multiply-single', filepath=f\"{autocog_home}/library/arithmetic/multiply-single.sta\"),\n",
    "    arch.load('arithmetic-multiply-chain',  filepath=f\"{autocog_home}/library/arithmetic/multiply-chain.sta\")\n",
    "]\n",
    "\n",
    "arith_data = [\n",
    "    {\n",
    "        \"problem\" : \"What is the product of 392 and 42?\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e18b7dfa-870e-402c-9182-39835c97a0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO node prefixed by prompt name\n",
    "# dotstr = '\\n'.join([ prompt.toGraphViz_concrete() for prompt in arith_cogs[0].prompts.values() ])\n",
    "# dotstr = arith_cogs[0].prompts['main'].instantiate(syntax=arch.syntax, stacks={}, branches={}, inputs=arith_data[0]).toGraphViz()\n",
    "# display(wrap_graphviz(dotstr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba3b7e1-a2a5-4df8-9c4f-3c943a423d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [\n",
    "    'mmlu-repeat', 'mmlu-repeat-cot', 'mmlu-repeat-hyp', 'mmlu-repeat-iter', 'mmlu-repeat-annot',\n",
    "    'mmlu-select', 'mmlu-select-cot', 'mmlu-select-hyp', 'mmlu-select-iter', 'mmlu-select-annot'\n",
    "]\n",
    "results = [ await arch(tag, **data) for tag in tags for data in mmlu_data ]\n",
    "# arith_results = [ await cog(**data) for cog in arith_cogs for data in arith_data ]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd250b0-58d1-4d09-8a8d-d860af8a8493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "scoring = lambda probas: numpy.power(numpy.prod(probas), 1./len(probas))\n",
    "texts = arch.orchestrator.pages[-1].ftts['main'][-1].results(lm)\n",
    "for text in texts:\n",
    "    print(f\"p={text[1]}\\n{text[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5ec2ff-e157-4e82-bba6-4c5b11f52aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch.orchestrator.pages[-1]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "057d8ed3-6f73-48aa-ba54-4dea2adfe325",
   "metadata": {
    "tags": []
   },
   "source": [
    "# source = \"\"\"\n",
    "# format bool {\n",
    "#     is enum(\"true\",\"false\");\n",
    "# }\n",
    "# prompt main {\n",
    "#     is {\n",
    "#         A is bool;\n",
    "#         B[0:2] is {\n",
    "#             C is bool;\n",
    "#             D[2:4] is bool;\n",
    "#         }\n",
    "#         E[0:2] is {\n",
    "#           F is bool;\n",
    "#         }\n",
    "#         G is {\n",
    "#           H is bool;\n",
    "#           I is bool;\n",
    "#         }\n",
    "#         J is bool;\n",
    "#     }\n",
    "#     channel {\n",
    "#         to .B.C from ?inC;\n",
    "#         to .E   from ?inE;\n",
    "#         to .G   from ?inG;\n",
    "#     }\n",
    "# }\"\"\"\n",
    "# samples = [\n",
    "#     (\n",
    "#       {},\n",
    "#       {\n",
    "#         \"inC\" : [ 'true', 'false' ],\n",
    "#         \"inE\" : [ { 'F' : 'true' } ],\n",
    "#         \"inG\" : { 'H' : 'true' }\n",
    "#       }\n",
    "#     ),\n",
    "#     (\n",
    "#       {},\n",
    "#       {\n",
    "#         \"inC\" : [ 'true' ],\n",
    "#         \"inE\" : [],\n",
    "#         \"inG\" : { 'H' : 'true' }\n",
    "#       }\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "source = \"\"\"\n",
    "prompt main {\n",
    "    is {\n",
    "        topic is text<20>;\n",
    "        question is text<50>;\n",
    "        choices[4] is {\n",
    "            value is text<40>;\n",
    "            correct is enum(\"yes\",\"no\");\n",
    "        }\n",
    "        answer is repeat(.choices.value);\n",
    "    }\n",
    "    channel {\n",
    "        to .topic         from ?topic;\n",
    "        to .question      from ?question;\n",
    "        to .choices.value from ?choices;\n",
    "    }\n",
    "    return {\n",
    "        from .answer;\n",
    "    }\n",
    "    annotate {\n",
    "        _ as \"You are answering a multiple choice questionnaire.\";\n",
    "        .topic           as \"the general category from which the question was taken\";\n",
    "        .question        as \"the question that you have to answer\";\n",
    "        .choices         as \"you judge whether each choice is correct or not\";\n",
    "        .choices.value   as \"the value of the choice\";\n",
    "        .choices.correct as \"you decide whether this choice is correct or not\";\n",
    "        .answer          as \"you repeat the value of the choice that best answer the question\";\n",
    "    }\n",
    "}\"\"\"\n",
    "samples = [\n",
    "    (\n",
    "        {},\n",
    "        {\n",
    "            \"topic\" : \"the topic of the question\",\n",
    "            \"question\" : \"an exmaple question to show how it compiles\",\n",
    "            \"choices\" : [\n",
    "                \"the first choice\",\n",
    "                \"the 2nd choice\",\n",
    "                \"yet another 3rd choice\",\n",
    "                \"final 4th choice\"\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "]\n",
    "\n",
    "source = \"\"\"\n",
    "prompt main {\n",
    "    is {\n",
    "        choices[4] is text<40>;\n",
    "        thought[1:3] is text<5>;\n",
    "        answer is repeat(.choices);\n",
    "    }\n",
    "    channel {\n",
    "        to .choices from ?choices;\n",
    "    }\n",
    "    return {\n",
    "        from .answer;\n",
    "    }\n",
    "    annotate {\n",
    "        _ as \"You are answering a multiple choice questionnaire.\";\n",
    "        .choices as \"possible choices\";\n",
    "        .thought as \"think about the choices\";\n",
    "        .answer  as \"repeat the correct choice\";\n",
    "    }\n",
    "}\"\"\"\n",
    "samples = [\n",
    "    (\n",
    "        {},\n",
    "        {\n",
    "            \"choices\" : [\n",
    "                \"first\",\n",
    "                \"second\",\n",
    "                \"third\",\n",
    "                \"fourth\"\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "]\n",
    "\n",
    "# source = \"\"\"\n",
    "# prompt main {\n",
    "#     is {\n",
    "#         choices[4] is text<40>;\n",
    "#         answer is repeat(.choices);\n",
    "#     }\n",
    "#     channel {\n",
    "#         to .choices from ?choices;\n",
    "#     }\n",
    "#     return {\n",
    "#         from .answer;\n",
    "#     }\n",
    "#     annotate {\n",
    "#         _ as \"You are answering a multiple choice questionnaire.\";\n",
    "#         .choices as \"possible choices\";\n",
    "#         .answer  as \"repeat the correct choice\";\n",
    "#     }\n",
    "# }\"\"\"\n",
    "# samples = [\n",
    "#     (\n",
    "#         {},\n",
    "#         {\n",
    "#             \"choices\" : [\n",
    "#                 \"first\",\n",
    "#                 \"second\",\n",
    "#                 \"third\",\n",
    "#                 \"fourth\"\n",
    "#             ]\n",
    "#         }\n",
    "#     )\n",
    "# ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
