{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1f5bc0f-bd79-4645-b471-2d53b11a6559",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datasets trl einops tokenizers sentencepiece peft\n",
    "#!pip uninstall -y transformers\n",
    "#!pip install git+https://github.com/huggingface/transformers\n",
    "#!pip install --upgrade protobuf\n",
    "\n",
    "import os, sys, json, copy\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION']='python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30b95bc4-2bb3-4ffa-8931-5e3b2624c3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Package `llama_cpp` needed for LLaMa wrapper (pip install git+https://github.com/tristanvdb/llama-cpp-python@choice-dev)\n",
      "Warning: Package `openai` and `tiktoken` needed for OpenAI wrapper (`pip install openai tiktoken`)\n"
     ]
    }
   ],
   "source": [
    "from autocog import CogArch\n",
    "from autocog.architecture.utility import PromptTee\n",
    "arch = CogArch(pipe=PromptTee(prefix='mmlu', tee=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43b13648-0e58-4584-9230-fb5ccee72d83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "from autocog.lm import TfLM\n",
    "kwargs = TfLM.create(model_path='gpt2-medium', device='cpu')\n",
    "llm = TfLM(**kwargs, completion_kwargs={ 'max_new_tokens' : 20 })\n",
    "arch.orchestrator.LMs.update({ 'text' : llm })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c5895d1-c601-4ea0-ac83-ea84d1dd2a43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "program=\"\"\"\\\n",
    "preamble: You are taking the MMLU Examination, a multiple choice questionnaire on a broad variety of subjects. For each question, you must pick the correct answer from four choices.\n",
    "basics: The following questionnaire present one question from the exam. As an expert in the domain, you will select the correct answer.\n",
    "\n",
    "entry(mmlu_choice): Your method is to first evaluate each choice separately, then decide on the correct solution.\n",
    "\n",
    "formats:\n",
    "- choice(repeat=.choices): Repeat the correct answer\n",
    "\n",
    "prompt(mmlu_choice):\n",
    "- target(topic) source(?topic)\n",
    "- target(question) source(?question)\n",
    "- target(choices) source(?choices){ground_truth_channels}\n",
    "> topic: the topic of the question\n",
    "> question: the question from the MMLU on topic specified above\n",
    "> choices[4]: List of four choices, a single one of them answer the question correctly\n",
    "> answer(choice): Which choice is correct? Repeat the correct answer\n",
    "__exit(answer):\n",
    "\n",
    "?ground_truth_channels=\n",
    "\"\"\"\n",
    "\n",
    "cog = arch.load(tag='template', language='sta', program=program, ground_truth_channels=\"\\n- target(answer) source(?answer)\")\n",
    "cog = arch.load(tag='actual',   language='sta', program=program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25023dc2-f6e4-41f6-84be-6f40c5dbf112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO move to CogArch once fleshed out\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "async def gen_prompt_dataset(arch, data, ground_truth_formater):\n",
    "    pipe = arch.orchestrator.pipe\n",
    "    arch.orchestrator.pipe = None\n",
    "    res = []\n",
    "    for (out,fid) in await arch.run([ ground_truth_formater(**sample) for sample in data ]):\n",
    "        for prompts in arch.orchestrator.frames[fid].prompts.values():\n",
    "            res += prompts\n",
    "    arch.orchestrator.pipe = pipe\n",
    "    return Dataset.from_dict({ 'text' : res })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a46c51c-db47-4ab5-8f3d-511ece60e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import mmlu_list, mmlu_subset\n",
    "\n",
    "def mmlu_truth_formater(topic, question, choices, answer, repeat=True, **kwargs):\n",
    "    answer = ord(answer)-ord('A')\n",
    "    if repeat:\n",
    "        answer = choices[answer]\n",
    "    return { 'tag' : 'template', 'topic' : topic, 'question' : question, 'choices' : choices, 'answer' : answer }\n",
    "\n",
    "data = json.load(open('/home/ubuntu/mmlu-data.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "510f9bbd-8163-477d-af58-e8abdbb85ab9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_topics = ['mc_test','science_elementary','science_middle','arc_easy','arc_hard','obqa']\n",
    "# mmlu_list(mmlu_subset(data, mode='aux', topic=train_topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d28364-17ea-4add-8862-1d55c88f3072",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = await gen_prompt_dataset(arch, data=mmlu_subset(data, topic=train_topics, mode='aux'), ground_truth_formater=mmlu_truth_formater)\n",
    "valid_ds = await gen_prompt_dataset(arch, data=mmlu_subset(data, topic=None, mode='dev'), ground_truth_formater=mmlu_truth_formater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36045a2f-78e6-4126-a844-9fdf70f74d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "llm.tokenizer.pad_token = llm.tokenizer.eos_token\n",
    "trainer = SFTTrainer(\n",
    "    llm.model,\n",
    "    tokenizer=llm.tokenizer,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=valid_ds,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=512,\n",
    "    args=TrainingArguments(\n",
    "        output_dir='/home/ubuntu/finetuning',\n",
    "        evaluation_strategy='steps',\n",
    "        warmup_steps=500,\n",
    "        eval_steps=500,\n",
    "        save_steps=500,\n",
    "        num_train_epochs=30\n",
    "    )\n",
    ")\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
