{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1f5bc0f-bd79-4645-b471-2d53b11a6559",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datasets trl einops tokenizers sentencepiece peft\n",
    "#!pip uninstall -y transformers\n",
    "#!pip install git+https://github.com/huggingface/transformers\n",
    "#!pip install --upgrade protobuf\n",
    "#!pip install git+https://github.com/LLNL/AutoCog@v0.2\n",
    "\n",
    "import os, sys, json, copy\n",
    "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION']='python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25023dc2-f6e4-41f6-84be-6f40c5dbf112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "# TODO move to CogArch once fleshed out\n",
    "\n",
    "import itertools\n",
    "import copy\n",
    "from datasets import Dataset\n",
    "\n",
    "async def gen_prompt_dataset(arch, tags, data, formater_input, formater_output):\n",
    "    workload = list(itertools.product(tags,data))\n",
    "    commands = []\n",
    "    for (tag,sample) in workload:\n",
    "        job = formater_input(tag=tag, **sample)\n",
    "        job.update(formater_output(tag=tag, **sample))\n",
    "        job.update({ 'tag' : f\"{tag}-train\" })\n",
    "        commands.append(job)\n",
    "    res = []\n",
    "    for (out,fid) in await arch.run(commands):\n",
    "        # TODO scan frames recursively\n",
    "        for prompts in arch.orchestrator.frames[fid].prompts.values():\n",
    "            res += prompts\n",
    "    return Dataset.from_dict({ 'text' : res })\n",
    "\n",
    "async def run_test(arch, tags, data, formater, checker):\n",
    "    workload = list(itertools.product(tags,data))\n",
    "    commands = []\n",
    "    for (tag,sample) in workload:\n",
    "        job = formater(tag=tag, **sample)\n",
    "        job.update({ 'tag' : f\"{tag}-train\" })\n",
    "        commands.append(job)\n",
    "\n",
    "    results = []\n",
    "    stats = {}\n",
    "    for ((tag,sample),(out,fid)) in zip(workload, await arch.run(commands)):\n",
    "        res = copy.deepcopy(sample)\n",
    "        res.update({ 'tag' : tag, 'out' : out, 'fid' : fid, 'res' : checker(tag, sample, out) })\n",
    "        results.append(res)\n",
    "        idx = (tag,sample['topic'])\n",
    "        if not idx in stats:\n",
    "            stats.update({ idx : { 'pass' : 0, 'fail' : 0 } })\n",
    "        stats[idx]['pass' if res['res'] else 'fail'] += 1\n",
    "\n",
    "    scores = {}\n",
    "    passfail = { tag : [0,0] for tag in tags }\n",
    "    for ((tag,topic),res) in stats.items():\n",
    "        if not topic in scores:\n",
    "            scores.update({ topic : {} })\n",
    "        passfail[tag][0] += res['pass']\n",
    "        passfail[tag][1] += res['fail']\n",
    "        scores[topic].update({ tag : res['pass']*1./(res['pass']+res['fail']) })\n",
    "    scores.update({ 'TOTAL' : { tag : passfail[tag][0]*1./(passfail[tag][0]+passfail[tag][1]) for tag in tags } })\n",
    "    return (results,scores)\n",
    "\n",
    "# TODO move to autcog/utility/pynb.py\n",
    "\n",
    "import tabulate\n",
    "\n",
    "def scores_to_table(tags, scores):\n",
    "    table = [ [ 'TOPIC' ] + [ tag for tag in tags ] ]\n",
    "    for (topic,score) in scores.items():\n",
    "        table.append([topic]+[score[tag] for tag in tags ])\n",
    "    return tabulate.tabulate(table, tablefmt='html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a46c51c-db47-4ab5-8f3d-511ece60e221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Package `llama_cpp` needed for LLaMa wrapper (pip install git+https://github.com/tristanvdb/llama-cpp-python@choice-dev)\n",
      "Warning: Package `openai` and `tiktoken` needed for OpenAI wrapper (`pip install openai tiktoken`)\n"
     ]
    }
   ],
   "source": [
    "# TODO move to ./utility.py once fleshed out\n",
    "\n",
    "from utility import mmlu_list, mmlu_subset, mcq_checkers, mmlu_exec\n",
    "\n",
    "def mmlu_formater_input(tag, topic, question, choices, **kwargs):\n",
    "    if tag.find('seqannot') >= 0:\n",
    "        choices = [ { 'candidate' : choice }  for (c,choice) in enumerate(choices) ]\n",
    "    return { 'topic' : topic, 'question' : question, 'choices' : choices }\n",
    "\n",
    "def mmlu_formater_output(tag, choices, answer, **kwargs):\n",
    "    a = ord(answer)-ord('A')\n",
    "    if tag.endswith('repeat'):\n",
    "        answer = choices[a]\n",
    "    if tag.find('seqannot') >= 0:\n",
    "        choices = [ { 'candidate' : choice, 'correct' : c == a }  for (c,choice) in enumerate(choices) ]\n",
    "    return { 'answer' : answer, 'choices' : choices }\n",
    "\n",
    "def mmlu_formater_inout(tag, **kwargs):\n",
    "    res = mmlu_formater_input(tag, **kwargs)\n",
    "    res.update(mmlu_formater_output(tag, **kwargs))\n",
    "    return res\n",
    "\n",
    "def mmlu_checker(tag, sample, result):\n",
    "    answer = ord(sample['answer'])-ord('A')\n",
    "    if tag.endswith('repeat'):\n",
    "        answer = sample['choices'][answer]\n",
    "    else:\n",
    "        answer = str(answer)\n",
    "    return result['answer'] == answer\n",
    "\n",
    "def mmlu_load_program_for_finetuning(arch, tag, program, output_channels, language='sta', **kwargs):\n",
    "    arch.load(tag=f'{tag}-train', language=language, program=program, **kwargs, output_channels=output_channels)\n",
    "    arch.load(tag=f'{tag}-test',  language=language, program=program, **kwargs, output_channels=[''] * len(output_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c5895d1-c601-4ea0-ac83-ea84d1dd2a43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from autocog import CogArch\n",
    "from autocog.architecture.utility import PromptTee\n",
    "\n",
    "programs = { 'inout' : \"\"\"\\\n",
    "preamble: You are taking the MMLU Examination, a multiple choice questionnaire on a broad variety of subjects. For each question, you must pick the correct answer from four choices.\n",
    "basics: The following questionnaire present one question from the exam. As an expert in the domain, you will select the correct answer.\n",
    "\n",
    "entry(mmlu_choice):\n",
    "\n",
    "formats:\n",
    "- choice({choice_mode}=.choices): {choice_desc}\n",
    "\n",
    "prompt(mmlu_choice):\n",
    "- target(topic) source(?topic)\n",
    "- target(question) source(?question)\n",
    "- target(choices) source(?choices){output_channels[0]}\n",
    "> topic: the topic of the question\n",
    "> question: the question from the MMLU on topic specified above\n",
    "> choices[4]: List of four choices, a single one of them answer the question correctly\n",
    "> answer(choice): Which choice is correct? {choice_desc}\n",
    "__exit(answer):\n",
    "\"\"\",\n",
    "            'seqannot' : \"\"\"\\\n",
    "preamble: You are taking the MMLU Examination, a multiple choice questionnaire on a broad variety of subjects. For each question, you must pick the correct answer from four choices.\n",
    "basics: The following questionnaire present one question from the exam. As an expert in the domain, you will select the correct answer.\n",
    "\n",
    "entry(mmlu_choice): Your method is to first evaluate each choice one by one as they get presented to you, then decide on the correct solution.\n",
    "\n",
    "formats:\n",
    "- choice({choice_mode}=.choices.candidate): {choice_desc}\n",
    "\n",
    "prompt(mmlu_choice):\n",
    "- target(topic) source(?topic)\n",
    "- target(question) source(?question)\n",
    "- target(choices) source(?choices){output_channels[0]}\n",
    "> topic: the topic of the question\n",
    "> question: the question from the MMLU on topic specified above\n",
    "> choices[4](record): For each choice, you judge whether it is the correct choice or not\n",
    "> > candidate: one of the possible answer for this question\n",
    "> > correct(bool): do you think that this is the correct answer?\n",
    "> answer(choice): Which choice is correct? {choice_desc}\n",
    "__exit(answer):\n",
    "\"\"\"}\n",
    "\n",
    "output_channels = { \n",
    "    'inout'    : [\"\\n- target(answer) source(?answer)\"],\n",
    "    'seqannot' : [\"\\n- target(answer) source(?answer)\"],\n",
    "}\n",
    "\n",
    "arch = CogArch() # pipe=PromptTee(prefix='mmlu', tee=sys.stdout)\n",
    "tags = []\n",
    "for (tag,program) in programs.items():\n",
    "    tags.append(f'{tag}-repeat')\n",
    "    mmlu_load_program_for_finetuning(arch, tag=f'{tag}-repeat', program=program, choice_mode='repeat', choice_desc=\"Repeat the correct answer verbatim\", output_channels=[\"\\n- target(answer) source(?answer)\"])\n",
    "    tags.append(f'{tag}-select')\n",
    "    mmlu_load_program_for_finetuning(arch, tag=f'{tag}-select', program=program, choice_mode='select', choice_desc=\"Index of the correct answer (1, 2, 3, or 4)\", output_channels=[\"\\n- target(answer) source(?answer)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "933b636f-355d-444e-9a8e-acd3a6cc1a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = mmlu_data()\n",
    "data = json.load(open('/home/ubuntu/mmlu-data.json'))\n",
    "\n",
    "train_subset = mmlu_subset(data, topic=['mc_test','science_elementary','science_middle','arc_easy','arc_hard','obqa'], mode='aux')\n",
    "valid_subset = mmlu_subset(data, topic=None, mode='dev')\n",
    "test_subset  = mmlu_subset(data, topic=None, mode='test')\n",
    "\n",
    "# mmlu_list(mmlu_subset(data, mode='aux', topic=train_topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dfc52a6-0016-4892-8873-27ec22ca31e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# arch.cogs.keys()\n",
    "\n",
    "# pipe = PromptTee(prefix='mmlu', tee=sys.stdout)\n",
    "# arch.orchestrator.pipe = PromptTee(prefix='mmlu', tee=sys.stdout)\n",
    "# tag = 'seqannot-repeat'\n",
    "# sample = data[0]\n",
    "# inputs = mmlu_formater_inout(tag, **sample)\n",
    "# print(f\"inputs={inputs}\")\n",
    "# await arch(f\"{tag}-train\", **inputs)\n",
    "# arch.orchestrator.pipe = None\n",
    "\n",
    "# arch.orchestrator.pipe = None\n",
    "# for tag in tags:\n",
    "#     for sample in data:\n",
    "#         try:\n",
    "#             inputs = mmlu_formater_input(tag, **sample)\n",
    "#             inputs.update(mmlu_formater_output(tag, **sample))\n",
    "#             inputs.update({ 'tag' : f\"{tag}-train\" })\n",
    "#             await arch.run([inputs], progress=False)\n",
    "#         except:\n",
    "#             print(f\"tag={tag}\")\n",
    "#             arch.orchestrator.pipe = pipe\n",
    "#             inputs = mmlu_formater_input(tag, **sample)\n",
    "#             inputs.update(mmlu_formater_output(tag, **sample))\n",
    "#             inputs.update({ 'tag' : f\"{tag}-train\" })\n",
    "#             await arch.run([inputs])\n",
    "#             arch.orchestrator.pipe = None\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43b13648-0e58-4584-9230-fb5ccee72d83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from autocog.lm import TfLM\n",
    "kwargs = TfLM.create(model_path='gpt2-medium', device='cuda')\n",
    "llm = TfLM(**kwargs, completion_kwargs={ 'max_new_tokens' : 20 })\n",
    "arch.orchestrator.LMs.update({ 'text' : llm })\n",
    "\n",
    "llm.tokenizer.pad_token = llm.tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f57b6aac-c131-4ef6-94dd-a0252b1d42f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44044/44044 [00:58<00:00, 756.56it/s] \n",
      "100%|██████████| 1140/1140 [00:01<00:00, 760.01it/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds = await gen_prompt_dataset(arch, tags=tags, data=train_subset, formater_input=mmlu_formater_input, formater_output=mmlu_formater_output)\n",
    "valid_ds = await gen_prompt_dataset(arch, tags=tags, data=valid_subset, formater_input=mmlu_formater_input, formater_output=mmlu_formater_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36045a2f-78e6-4126-a844-9fdf70f74d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/44044 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36201' max='55060' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36201/55060 9:39:04 < 5:01:41, 1.04 it/s, Epoch 6.57/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.398800</td>\n",
       "      <td>0.640763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.453900</td>\n",
       "      <td>0.638973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.442800</td>\n",
       "      <td>0.646160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.417800</td>\n",
       "      <td>0.658638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.410500</td>\n",
       "      <td>0.665569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.391900</td>\n",
       "      <td>0.674477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.354900</td>\n",
       "      <td>0.685426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.339300</td>\n",
       "      <td>0.693093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.319500</td>\n",
       "      <td>0.691979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.312100</td>\n",
       "      <td>0.706165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.300600</td>\n",
       "      <td>0.708813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.290600</td>\n",
       "      <td>0.719430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.275500</td>\n",
       "      <td>0.720331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.264200</td>\n",
       "      <td>0.724101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.254100</td>\n",
       "      <td>0.734366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.243000</td>\n",
       "      <td>0.741199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.235800</td>\n",
       "      <td>0.752373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.225400</td>\n",
       "      <td>0.740055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.223700</td>\n",
       "      <td>0.750130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.210300</td>\n",
       "      <td>0.779855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.205000</td>\n",
       "      <td>0.792628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.196300</td>\n",
       "      <td>0.792580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.193700</td>\n",
       "      <td>0.804293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.188600</td>\n",
       "      <td>0.809503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.184600</td>\n",
       "      <td>0.833507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.179300</td>\n",
       "      <td>0.849476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.178800</td>\n",
       "      <td>0.825557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.161100</td>\n",
       "      <td>0.903257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.150500</td>\n",
       "      <td>0.885497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.150800</td>\n",
       "      <td>0.919695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.145400</td>\n",
       "      <td>0.912364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.139400</td>\n",
       "      <td>0.924758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.142100</td>\n",
       "      <td>0.913418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.141000</td>\n",
       "      <td>0.934597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.137200</td>\n",
       "      <td>0.946489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.134900</td>\n",
       "      <td>0.958469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.127200</td>\n",
       "      <td>0.949378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>0.975785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>0.126300</td>\n",
       "      <td>0.956605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.125400</td>\n",
       "      <td>0.975376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>0.123100</td>\n",
       "      <td>1.039828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.119100</td>\n",
       "      <td>1.034986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>0.119100</td>\n",
       "      <td>1.034528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>0.116400</td>\n",
       "      <td>1.033514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.112300</td>\n",
       "      <td>1.025615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>0.110800</td>\n",
       "      <td>1.046633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>0.110400</td>\n",
       "      <td>1.070573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.107100</td>\n",
       "      <td>1.043412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>1.044383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.104200</td>\n",
       "      <td>1.071463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>0.100600</td>\n",
       "      <td>1.089311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>1.094773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>0.096800</td>\n",
       "      <td>1.100135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>0.096700</td>\n",
       "      <td>1.088477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.097200</td>\n",
       "      <td>1.120701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>0.082700</td>\n",
       "      <td>1.158084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11400</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>1.178490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>1.153411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11800</td>\n",
       "      <td>0.078700</td>\n",
       "      <td>1.169355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.077900</td>\n",
       "      <td>1.162295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12200</td>\n",
       "      <td>0.078300</td>\n",
       "      <td>1.137257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12400</td>\n",
       "      <td>0.075200</td>\n",
       "      <td>1.175393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12600</td>\n",
       "      <td>0.076200</td>\n",
       "      <td>1.180635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>0.074700</td>\n",
       "      <td>1.161692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>1.184036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>0.074300</td>\n",
       "      <td>1.166201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13400</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>1.179073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13600</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>1.190353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13800</td>\n",
       "      <td>0.070600</td>\n",
       "      <td>1.192128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>1.192744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14200</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>1.207352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14400</td>\n",
       "      <td>0.066800</td>\n",
       "      <td>1.178303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14600</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>1.206686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14800</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>1.214095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.065200</td>\n",
       "      <td>1.210524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15200</td>\n",
       "      <td>0.065100</td>\n",
       "      <td>1.231304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15400</td>\n",
       "      <td>0.063200</td>\n",
       "      <td>1.235585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15600</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>1.228500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15800</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>1.238380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.059400</td>\n",
       "      <td>1.231251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16200</td>\n",
       "      <td>0.059600</td>\n",
       "      <td>1.244117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16400</td>\n",
       "      <td>0.058900</td>\n",
       "      <td>1.234517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16600</td>\n",
       "      <td>0.056100</td>\n",
       "      <td>1.244194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16800</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>1.253148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.053800</td>\n",
       "      <td>1.243356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17200</td>\n",
       "      <td>0.052400</td>\n",
       "      <td>1.261505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17400</td>\n",
       "      <td>0.051700</td>\n",
       "      <td>1.256236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17600</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>1.272018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17800</td>\n",
       "      <td>0.050700</td>\n",
       "      <td>1.273417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.051700</td>\n",
       "      <td>1.255961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18200</td>\n",
       "      <td>0.052300</td>\n",
       "      <td>1.259226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18400</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1.266624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18600</td>\n",
       "      <td>0.050500</td>\n",
       "      <td>1.280950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18800</td>\n",
       "      <td>0.050100</td>\n",
       "      <td>1.256093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.049900</td>\n",
       "      <td>1.281419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19200</td>\n",
       "      <td>0.049700</td>\n",
       "      <td>1.280223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19400</td>\n",
       "      <td>0.049400</td>\n",
       "      <td>1.288827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19600</td>\n",
       "      <td>0.048300</td>\n",
       "      <td>1.280282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19800</td>\n",
       "      <td>0.049100</td>\n",
       "      <td>1.276010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.048700</td>\n",
       "      <td>1.295937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20200</td>\n",
       "      <td>0.048600</td>\n",
       "      <td>1.282502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20400</td>\n",
       "      <td>0.048300</td>\n",
       "      <td>1.285699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20600</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>1.277675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20800</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>1.280034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.046600</td>\n",
       "      <td>1.287946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21200</td>\n",
       "      <td>0.046700</td>\n",
       "      <td>1.293039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21400</td>\n",
       "      <td>0.046100</td>\n",
       "      <td>1.292974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21600</td>\n",
       "      <td>0.045300</td>\n",
       "      <td>1.298256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21800</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>1.299210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>1.301616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22200</td>\n",
       "      <td>0.042600</td>\n",
       "      <td>1.312043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22400</td>\n",
       "      <td>0.041800</td>\n",
       "      <td>1.313626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22600</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>1.318878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22800</td>\n",
       "      <td>0.042600</td>\n",
       "      <td>1.317114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>1.302705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23200</td>\n",
       "      <td>0.041600</td>\n",
       "      <td>1.324822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23400</td>\n",
       "      <td>0.041800</td>\n",
       "      <td>1.325934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23600</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>1.309874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23800</td>\n",
       "      <td>0.042400</td>\n",
       "      <td>1.321540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>1.295572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24200</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>1.334770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24400</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>1.321520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24600</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>1.327252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24800</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>1.328208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>1.320844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25200</td>\n",
       "      <td>0.041100</td>\n",
       "      <td>1.333026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25400</td>\n",
       "      <td>0.041100</td>\n",
       "      <td>1.325699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25600</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>1.326627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25800</td>\n",
       "      <td>0.040600</td>\n",
       "      <td>1.336044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.040500</td>\n",
       "      <td>1.333385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26200</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>1.333039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26400</td>\n",
       "      <td>0.040300</td>\n",
       "      <td>1.325063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26600</td>\n",
       "      <td>0.040300</td>\n",
       "      <td>1.337631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26800</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1.330457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.039600</td>\n",
       "      <td>1.331683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27200</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1.319451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27400</td>\n",
       "      <td>0.039600</td>\n",
       "      <td>1.334062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27600</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>1.342492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27800</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>1.335690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>1.339354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28200</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>1.345267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28400</td>\n",
       "      <td>0.037600</td>\n",
       "      <td>1.347481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28600</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>1.348218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28800</td>\n",
       "      <td>0.037600</td>\n",
       "      <td>1.355883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.037600</td>\n",
       "      <td>1.344065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29200</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>1.352895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29400</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>1.352750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29600</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>1.353998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29800</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>1.354176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>1.353130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30200</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>1.348779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30400</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>1.362909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30600</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>1.359516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30800</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>1.366312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>1.364111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31200</td>\n",
       "      <td>0.037100</td>\n",
       "      <td>1.355600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31400</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>1.373022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31600</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>1.369133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31800</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>1.371662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>1.368543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32200</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>1.364479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32400</td>\n",
       "      <td>0.036500</td>\n",
       "      <td>1.369313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32600</td>\n",
       "      <td>0.036300</td>\n",
       "      <td>1.377593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32800</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>1.366287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>1.367365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33200</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>1.385216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33400</td>\n",
       "      <td>0.035300</td>\n",
       "      <td>1.376444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33600</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>1.378963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33800</td>\n",
       "      <td>0.034900</td>\n",
       "      <td>1.389171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>1.385880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34200</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>1.385285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34400</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>1.377122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34600</td>\n",
       "      <td>0.034900</td>\n",
       "      <td>1.369893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34800</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>1.386411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>1.396056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35200</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>1.394861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35400</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>1.392157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35600</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>1.398813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35800</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>1.392629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.034600</td>\n",
       "      <td>1.381979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36200</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>1.393078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "from IPython.display import display\n",
    "\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "datadir    = '/home/ubuntu/finetuning-results'\n",
    "experiment = 'mmlu-gpt2-medium'\n",
    "\n",
    "# scores = [ (await run_test(arch, tags=tags, data=valid_subset, formater=mmlu_formater_input, checker=mmlu_checker))[1] ]\n",
    "# display(scores_to_table(tags, scores[-1]))\n",
    "\n",
    "n_steps = 200\n",
    "timestamp  = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "trainer = SFTTrainer(\n",
    "    llm.model,\n",
    "    tokenizer=llm.tokenizer,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=valid_ds,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=512,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=f'{datadir}/{experiment}/{timestamp}',\n",
    "        evaluation_strategy='steps',\n",
    "        warmup_steps=5*n_steps,\n",
    "        eval_steps=n_steps,\n",
    "        logging_steps=n_steps,\n",
    "        save_strategy='no',\n",
    "        save_steps=n_steps,\n",
    "        num_train_epochs=10,\n",
    "    )\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(f'{datadir}/{experiment}/{timestamp}/backup')\n",
    "\n",
    "scores.append( (await run_test(arch, tags=tags, data=valid_subset, formater=mmlu_formater_input, checker=mmlu_checker))[1] )\n",
    "display(scores_to_table(tags, scores[-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
